{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prepare Data - Download and Insert into Database\n",
        "\n",
        "This notebook downloads the green taxi trip data and taxi zone lookup data, then inserts them into the PostgreSQL database."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "from sqlalchemy import create_engine\n",
        "import urllib.request\n",
        "from pathlib import Path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Download Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# URLs for the datasets\n",
        "parquet_url = \"https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2025-11.parquet\"\n",
        "csv_url = \"https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv\"\n",
        "\n",
        "# Local file paths\n",
        "parquet_file = \"green_tripdata_2025-11.parquet\"\n",
        "csv_file = \"taxi_zone_lookup.csv\"\n",
        "\n",
        "# Download parquet file\n",
        "print(\"Downloading green taxi data...\")\n",
        "urllib.request.urlretrieve(parquet_url, parquet_file)\n",
        "print(f\"✓ Downloaded: {parquet_file}\")\n",
        "\n",
        "# Download CSV file\n",
        "print(\"Downloading taxi zone lookup data...\")\n",
        "urllib.request.urlretrieve(csv_url, csv_file)\n",
        "print(f\"✓ Downloaded: {csv_file}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Set up Database Connection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Database connection parameters\n",
        "# Update these with your actual database credentials\n",
        "DB_HOST = os.getenv('DB_HOST', 'localhost')\n",
        "DB_PORT = os.getenv('DB_PORT', '5432')\n",
        "DB_NAME = os.getenv('DB_NAME', 'ny_taxi')\n",
        "DB_USER = os.getenv('DB_USER', 'postgres')\n",
        "DB_PASSWORD = os.getenv('DB_PASSWORD', 'postgres')\n",
        "\n",
        "# Create connection string\n",
        "connection_string = f'postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}'\n",
        "\n",
        "# Create SQLAlchemy engine\n",
        "engine = create_engine(connection_string)\n",
        "\n",
        "print(\"Database connection established\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Read and Insert Green Taxi Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Read parquet file\n",
        "print(\"Reading parquet file...\")\n",
        "df_green = pd.read_parquet(parquet_file)\n",
        "print(f\"✓ Loaded {len(df_green):,} rows\")\n",
        "print(f\"\\nData types:\")\n",
        "print(df_green.dtypes)\n",
        "print(f\"\\nFirst few rows:\")\n",
        "df_green.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Fix datatypes for green taxi data\n",
        "print(\"Fixing datatypes...\")\n",
        "\n",
        "# Convert datetime columns (common column names in taxi data)\n",
        "datetime_columns = []\n",
        "for col in df_green.columns:\n",
        "    if 'datetime' in col.lower() or 'date' in col.lower() or 'time' in col.lower():\n",
        "        datetime_columns.append(col)\n",
        "        df_green[col] = pd.to_datetime(df_green[col], errors='coerce')\n",
        "        print(f\"  Converted {col} to datetime\")\n",
        "\n",
        "# Convert numeric columns that might be strings\n",
        "numeric_columns = ['passenger_count', 'trip_distance', 'fare_amount', 'extra', 'mta_tax', \n",
        "                   'tip_amount', 'tolls_amount', 'improvement_surcharge', 'total_amount', \n",
        "                   'congestion_surcharge', 'ehail_fee']\n",
        "for col in numeric_columns:\n",
        "    if col in df_green.columns:\n",
        "        df_green[col] = pd.to_numeric(df_green[col], errors='coerce')\n",
        "        print(f\"  Converted {col} to numeric\")\n",
        "\n",
        "# Display updated datatypes\n",
        "print(\"\\nUpdated data types:\")\n",
        "print(df_green.dtypes)\n",
        "print(f\"\\nSample of converted data:\")\n",
        "df_green.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Insert into public.green_taxi_data\n",
        "# Using if_exists='replace' to replace existing data, change to 'append' if you want to keep existing data\n",
        "print(\"Inserting data into public.green_taxi_data...\")\n",
        "df_green.to_sql(name='green_taxi_data', \n",
        "                con=engine, \n",
        "                schema='public',\n",
        "                if_exists='replace',  # Change to 'append' if you want to add to existing data\n",
        "                index=False,\n",
        "                method='multi',  # Faster insertion\n",
        "                chunksize=10000)  # Insert in chunks\n",
        "print(\"✓ Data inserted successfully into public.green_taxi_data\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Read and Insert Taxi Zone Lookup Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Read CSV file\n",
        "print(\"Reading CSV file...\")\n",
        "df_zones = pd.read_csv(csv_file)\n",
        "print(f\"✓ Loaded {len(df_zones):,} rows\")\n",
        "print(f\"\\nData types:\")\n",
        "print(df_zones.dtypes)\n",
        "print(f\"\\nFirst few rows:\")\n",
        "df_zones.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Fix datatypes for taxi zone lookup data\n",
        "print(\"Fixing datatypes...\")\n",
        "\n",
        "# Convert LocationID to integer if it exists\n",
        "if 'LocationID' in df_zones.columns:\n",
        "    df_zones['LocationID'] = pd.to_numeric(df_zones['LocationID'], errors='coerce').astype('Int64')\n",
        "    print(f\"  Converted LocationID to integer\")\n",
        "\n",
        "# Ensure string columns are properly typed\n",
        "string_columns = ['Borough', 'Zone', 'service_zone']\n",
        "for col in string_columns:\n",
        "    if col in df_zones.columns:\n",
        "        df_zones[col] = df_zones[col].astype('string')\n",
        "        print(f\"  Converted {col} to string\")\n",
        "\n",
        "# Display updated datatypes\n",
        "print(\"\\nUpdated data types:\")\n",
        "print(df_zones.dtypes)\n",
        "print(f\"\\nSample of converted data:\")\n",
        "df_zones.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Insert into public.taxi_zone_lookup\n",
        "print(\"Inserting data into public.taxi_zone_lookup...\")\n",
        "df_zones.to_sql(name='taxi_zone_lookup', \n",
        "                con=engine, \n",
        "                schema='public',\n",
        "                if_exists='replace',  # Change to 'append' if you want to keep existing data\n",
        "                index=False)\n",
        "print(\"✓ Data inserted successfully into public.taxi_zone_lookup\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Verify Data Insertion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Verify green_taxi_data\n",
        "query_green = \"SELECT COUNT(*) as row_count FROM public.green_taxi_data;\"\n",
        "result_green = pd.read_sql(query_green, engine)\n",
        "print(f\"Rows in public.green_taxi_data: {result_green['row_count'].iloc[0]:,}\")\n",
        "\n",
        "# Verify taxi_zone_lookup\n",
        "query_zones = \"SELECT COUNT(*) as row_count FROM public.taxi_zone_lookup;\"\n",
        "result_zones = pd.read_sql(query_zones, engine)\n",
        "print(f\"Rows in public.taxi_zone_lookup: {result_zones['row_count'].iloc[0]:,}\")\n",
        "\n",
        "print(\"\\n✓ Data verification complete!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Query Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Run query and get result as DataFrame\n",
        "query = \"\"\"\n",
        "SELECT COUNT(*) as trips_count\n",
        "FROM public.green_taxi_data\n",
        "WHERE lpep_pickup_datetime >= '2025-11-01' \n",
        "  AND lpep_pickup_datetime < '2025-12-01'\n",
        "  AND trip_distance <= 1;\n",
        "\"\"\"\n",
        "\n",
        "result = pd.read_sql(query, engine)\n",
        "print(f\"Number of trips in November 2025 with distance <= 1 mile: {result['trips_count'].iloc[0]:,}\")\n",
        "result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Pickup day with the longest trip distance (trips < 100 miles to exclude data errors)\n",
        "query_longest = \"\"\"\n",
        "SELECT DATE(lpep_pickup_datetime) AS pickup_date,\n",
        "       MAX(trip_distance) AS max_trip_distance\n",
        "FROM public.green_taxi_data\n",
        "WHERE trip_distance < 100\n",
        "GROUP BY DATE(lpep_pickup_datetime)\n",
        "ORDER BY max_trip_distance DESC\n",
        "LIMIT 1;\n",
        "\"\"\"\n",
        "\n",
        "result_longest = pd.read_sql(query_longest, engine)\n",
        "pickup_date = result_longest['pickup_date'].iloc[0]\n",
        "max_dist = result_longest['max_trip_distance'].iloc[0]\n",
        "print(f\"Pickup day with longest trip: {pickup_date} (max distance: {max_dist:.2f} miles)\")\n",
        "result_longest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Drop-off zone with largest tip for pickups from \"East Harlem North\" in November 2025\n",
        "query_tip = \"\"\"\n",
        "SELECT tz_do.\"Zone\" AS dropoff_zone,\n",
        "       tz_do.\"Borough\" AS dropoff_borough,\n",
        "       SUM(g.tip_amount) AS total_tips\n",
        "FROM public.green_taxi_data g\n",
        "JOIN public.taxi_zone_lookup tz_pu ON g.\"PULocationID\" = tz_pu.\"LocationID\" AND tz_pu.\"Zone\" = 'East Harlem North'\n",
        "JOIN public.taxi_zone_lookup tz_do ON g.\"DOLocationID\" = tz_do.\"LocationID\"\n",
        "WHERE g.lpep_pickup_datetime >= '2025-11-01' \n",
        "  AND g.lpep_pickup_datetime < '2025-12-01'\n",
        "GROUP BY tz_do.\"Zone\", tz_do.\"Borough\"\n",
        "ORDER BY total_tips DESC\n",
        "LIMIT 1;\n",
        "\"\"\"\n",
        "\n",
        "result_tip = pd.read_sql(query_tip, engine)\n",
        "dropoff_zone = result_tip['dropoff_zone'].iloc[0]\n",
        "dropoff_borough = result_tip['dropoff_borough'].iloc[0]\n",
        "total_tips = result_tip['total_tips'].iloc[0]\n",
        "print(f\"Drop-off zone with largest tip (pickups from East Harlem North, Nov 2025): {dropoff_zone} ({dropoff_borough}) — ${total_tips:,.2f}\")\n",
        "print(result_tip)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Pickup zone with largest total_amount (sum) on November 18th, 2025\n",
        "query_zone = \"\"\"\n",
        "SELECT tz.\"Zone\" AS pickup_zone,\n",
        "       tz.\"Borough\" AS borough,\n",
        "       SUM(g.total_amount) AS total_amount_sum\n",
        "FROM public.green_taxi_data g\n",
        "JOIN public.taxi_zone_lookup tz ON g.\"PULocationID\" = tz.\"LocationID\"\n",
        "WHERE g.lpep_pickup_datetime >= '2025-11-18' \n",
        "  AND g.lpep_pickup_datetime < '2025-11-19'\n",
        "GROUP BY tz.\"Zone\", tz.\"Borough\"\n",
        "ORDER BY total_amount_sum DESC\n",
        "LIMIT 1;\n",
        "\"\"\"\n",
        "\n",
        "result_zone = pd.read_sql(query_zone, engine)\n",
        "pickup_zone = result_zone['pickup_zone'].iloc[0]\n",
        "borough = result_zone['borough'].iloc[0]\n",
        "total = result_zone['total_amount_sum'].iloc[0]\n",
        "print(f\"Pickup zone with largest total_amount on 2025-11-18: {pickup_zone} ({borough}) — ${total:,.2f}\")\n",
        "result_zone"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}